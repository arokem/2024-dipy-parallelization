{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸš§ Under construction ðŸš§\n",
        "\n",
        "# Abstract\n",
        "\n",
        "# Introduction\n",
        "\n",
        "# Methods\n",
        "\n",
        "# Results\n",
        "\n",
        "Parallelization with `ray` provided considerable speedups over serial excicution for both constrained sperical deconvolution models and free water models. We saw a much greater speedup for the free water model, which is possibly explained by the fact that it is much more computationally expensive per voxel. This would mean that the overhead from parallelizing the model would have a smaller effect on the runtime. Interestlingly 48 and 72 core instances performed slightly worse than the 32 core instance on the csdm model, which may indicate that there is some increased overhead for each core, separate from the overhead for each task sent to ray.\n",
        "\n",
        "![](figures/csdm_speedup.png){width=50% height=50%}\n",
        "![](figures/fwdtim_speedup.png){width=50% height=50%}\n",
        "\n",
        "Efficiency decreases as a function of number of CPUs, but is still rather high in many configurations. Efficiency is also considerably higher for the free water tensor model, which is consistent with out expectations given that it is more computationally expensive per voxel and therefor ray overhead would have less effect. The high efficency of 8 core machines suggest that the most cost effective configuration for processing may be relativly cheap low core machines.\n",
        "\n",
        "![](figures/csdm_efficency.png){width=50% height=50%}\n",
        "![](figures/fwdtim_efficency.png){width=50% height=50%}\n",
        "\n",
        "Ray tends to spill a large amount of data to disk and does not clean up afterwards. This can quickly become problematic when running multiple consecuitive models. Withing just an hour or two of running ray could easily spill over 500gb to disk. We have implemented a fix for this within our model as follows:\n"
      ],
      "id": "c3bc27f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "    if engine == \"ray\":\n",
        "        if not has_ray:\n",
        "            raise ray()\n",
        "\n",
        "        if clean_spill:\n",
        "            tmp_dir = tempfile.TemporaryDirectory()\n",
        "\n",
        "            if not ray.is_initialized():\n",
        "                ray.init(_system_config={\n",
        "                    \"object_spilling_config\": json.dumps(\n",
        "                        {\"type\": \"filesystem\", \"params\": {\"directory_path\":\n",
        "                         tmp_dir.name}},\n",
        "                    )\n",
        "                },)\n",
        "\n",
        "        func = ray.remote(func)\n",
        "        results = ray.get([func.remote(ii, *func_args, **func_kwargs)\n",
        "                          for ii in in_list])\n",
        "\n",
        "        if clean_spill:\n",
        "            shutil.rmtree(tmp_dir.name)"
      ],
      "id": "47a03146",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Discussion\n",
        "z\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "This work was funded through NIH grant EB027585 (PI: Eleftherios Garyfallidis) and\n",
        "a grant from the Chan Zuckerberg Initiative Essential Open Source Software program (PI: Serge Koudoro)."
      ],
      "id": "199cd292"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "dipy3.11",
      "language": "python",
      "display_name": "dipy3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}